{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP4Vp2pnITqDMypjC4Ly7Uh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GHdUKE_fa50h"},"outputs":[],"source":["!pip install transformers datasets torch torchvision torchtext"]},{"cell_type":"markdown","source":["# 1. Transformer"],"metadata":{"id":"fbsVOdZfcxQi"}},{"cell_type":"markdown","source":["## Install Packages"],"metadata":{"id":"33uh3Lj4c5dY"}},{"cell_type":"code","source":["import torch\n","from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n","from torchtext.datasets import WikiText2\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","import math\n","\n","# Device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"8EsxJNoRbCCW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Transformer Model (GPT-2)"],"metadata":{"id":"T0Nh9yC6bQvy"}},{"cell_type":"code","source":["gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n","gpt_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n","gpt_model.eval()"],"metadata":{"id":"xAe16nlAbOyU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"GZ1YtSHSb5fk"}},{"cell_type":"code","source":["# --- 2. Load WikiText2 Test Dataset ---\n","def get_text():\n","    return WikiText2(split='test')\n","\n","# Load text data\n","test_text = list(get_text())\n","\n","# Prepare sample batch\n","sample_text = \" \".join(test_text[:1000])\n","inputs = gpt_tokenizer(sample_text, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)"],"metadata":{"id":"FiHXd3fEcDnM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluate Transformer"],"metadata":{"id":"GZtl-qk6cN9D"}},{"cell_type":"code","source":["# Evaluate Transformer Model\n","with torch.no_grad():\n","    outputs = gpt_model(**inputs, labels=inputs[\"input_ids\"])\n","    loss = outputs.loss\n","    gpt2_ppl = math.exp(loss.item())\n","\n","print(f\"Transformer (GPT-2) Perplexity: {gpt2_ppl:.2f}\")"],"metadata":{"id":"LsS851tgbElT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. RNN-Based Language Model"],"metadata":{"id":"SR1bluHPcr9P"}},{"cell_type":"markdown","source":["## Install Packages"],"metadata":{"id":"ZQ9XM_S_dM-1"}},{"cell_type":"code","source":["from torchtext.models import RobertaBundle\n","from torchtext.models.lstm_lm import LSTMLanguageModel\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.utils.data import DataLoader"],"metadata":{"id":"fydp2GSMcvA8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Build Vocab from Training Data"],"metadata":{"id":"V5YZE-rxdYim"}},{"cell_type":"code","source":["tokenizer = get_tokenizer(\"basic_english\")\n","def yield_tokens(data_iter):\n","    for text in data_iter:\n","        yield tokenizer(text)\n","\n","vocab = build_vocab_from_iterator(yield_tokens(WikiText2(split='train')), specials=[\"<unk>\"])\n","vocab.set_default_index(vocab[\"<unk>\"])"],"metadata":{"id":"FFdAjoYwdSTs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prepare test dataset"],"metadata":{"id":"6GO6sD9pdaz6"}},{"cell_type":"code","source":["def data_process(raw_text_iter):\n","    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n","    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n","\n","test_data = data_process(WikiText2(split='test')).to(device)\n","\n","# Batchify\n","def batchify(data, bsz):\n","    seq_len = data.size(0) // bsz\n","    data = data[:seq_len * bsz]\n","    data = data.view(bsz, seq_len).t().contiguous()\n","    return data\n","\n","batch_size = 20\n","eval_batch_size = 10\n","test_data = batchify(test_data, eval_batch_size)"],"metadata":{"id":"cS8Z1S08dewn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load pretrained LSTM model"],"metadata":{"id":"Jg0maC1udpJQ"}},{"cell_type":"code","source":["lstm_model = LSTMLanguageModel(vocab_size=len(vocab), emsize=200, nhid=200, nlayers=2).to(device)\n","lstm_model.load_state_dict(torch.load(\"path_to_pretrained_lstm_model.pt\"))  # <-- You need this checkpoint\n","lstm_model.eval()"],"metadata":{"id":"EPkk1LEVdqeE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluate RNN Model\n"],"metadata":{"id":"qC_0IJ_bdstl"}},{"cell_type":"code","source":[" bptt = 35\n","def get_batch(source, i):\n","    seq_len = min(bptt, len(source) - 1 - i)\n","    data = source[i:i+seq_len]\n","    target = source[i+1:i+1+seq_len].reshape(-1)\n","    return data, target\n","\n","total_loss = 0.\n","ntokens = len(vocab)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","with torch.no_grad():\n","    for i in range(0, test_data.size(0) - 1, bptt):\n","        data, targets = get_batch(test_data, i)\n","        output = lstm_model(data)\n","        output_flat = output.view(-1, ntokens)\n","        total_loss += len(data) * criterion(output_flat, targets).item()\n","\n","lstm_ppl = math.exp(total_loss / (len(test_data) - 1))\n","print(f\"RNN (LSTM) Perplexity: {lstm_ppl:.2f}\")"],"metadata":{"id":"JyfkDMQwdxKU"},"execution_count":null,"outputs":[]}]}