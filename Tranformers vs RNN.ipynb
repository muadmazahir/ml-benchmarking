{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHdUKE_fa50h"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch torchvision torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbsVOdZfcxQi"
   },
   "source": [
    "# 1. Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33uh3Lj4c5dY"
   },
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8EsxJNoRbCCW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import math\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0Nh9yC6bQvy"
   },
   "source": [
    "## Load Transformer Model (GPT-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAe16nlAbOyU"
   },
   "outputs": [],
   "source": [
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "gpt_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "gpt_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZ1YtSHSb5fk"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FiHXd3fEcDnM"
   },
   "outputs": [],
   "source": [
    "# --- 2. Load WikiText2 Test Dataset ---\n",
    "def get_text():\n",
    "    return WikiText2(split='test')\n",
    "\n",
    "# Load text data\n",
    "test_text = list(get_text())\n",
    "\n",
    "# Prepare sample batch\n",
    "sample_text = \" \".join(test_text[:1000])\n",
    "inputs = gpt_tokenizer(sample_text, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZtl-qk6cN9D"
   },
   "source": [
    "## Evaluate Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsS851tgbElT"
   },
   "outputs": [],
   "source": [
    "# Evaluate Transformer Model\n",
    "with torch.no_grad():\n",
    "    outputs = gpt_model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "    gpt2_ppl = math.exp(loss.item())\n",
    "\n",
    "print(f\"Transformer (GPT-2) Perplexity: {gpt2_ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SR1bluHPcr9P"
   },
   "source": [
    "# 2. RNN-Based Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQ9XM_S_dM-1"
   },
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fydp2GSMcvA8"
   },
   "outputs": [],
   "source": [
    "from torchtext.models import RobertaBundle\n",
    "from torchtext.models.lstm_lm import LSTMLanguageModel\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5YZE-rxdYim"
   },
   "source": [
    "## Build Vocab from Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFdAjoYwdSTs"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(WikiText2(split='train')), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GO6sD9pdaz6"
   },
   "source": [
    "## Prepare test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cS8Z1S08dewn"
   },
   "outputs": [],
   "source": [
    "def data_process(raw_text_iter):\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "test_data = data_process(WikiText2(split='test')).to(device)\n",
    "\n",
    "# Batchify\n",
    "def batchify(data, bsz):\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg0maC1udpJQ"
   },
   "source": [
    "## Load pretrained LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPkk1LEVdqeE"
   },
   "outputs": [],
   "source": [
    "lstm_model = LSTMLanguageModel(vocab_size=len(vocab), emsize=200, nhid=200, nlayers=2).to(device)\n",
    "lstm_model.load_state_dict(torch.load(\"path_to_pretrained_lstm_model.pt\"))  # <-- You need this checkpoint\n",
    "lstm_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qC_0IJ_bdstl"
   },
   "source": [
    "## Evaluate RNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyfkDMQwdxKU"
   },
   "outputs": [],
   "source": [
    " bptt = 35\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target\n",
    "\n",
    "total_loss = 0.\n",
    "ntokens = len(vocab)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, test_data.size(0) - 1, bptt):\n",
    "        data, targets = get_batch(test_data, i)\n",
    "        output = lstm_model(data)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "\n",
    "lstm_ppl = math.exp(total_loss / (len(test_data) - 1))\n",
    "print(f\"RNN (LSTM) Perplexity: {lstm_ppl:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP4Vp2pnITqDMypjC4Ly7Uh",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
